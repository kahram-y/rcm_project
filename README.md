# AutoInt_MLP 모델 튜닝 실험 보고서

본 프로젝트에서는 하이퍼파라미터 최적화를 통해 모델의 과적합을 방지하고, 추천 시스템의 주요 성능 지표인 **Hit Rate**와 **NDCG**를 개선하였습니다.

---

## 주요 하이퍼파라미터 변경 사항

모델의 표현력을 높이고 안정적인 수렴을 위해 다음과 같이 파라미터를 조정하였습니다.

| 파라미터 | 변경 전 | 변경 후 | 기대 효과 |
|:---:|:---:|:---:|:---|
| **임베딩 크기** | 16 | **32** | 피처의 잠재적 표현력 증가 |
| **학습률 (LR)** | 0.0001 | **0.0005** | 정교한 수렴 및 최적점 도달 |
| **배치 사이즈** | 2048 | **1024** | 가중치 업데이트 빈도 증가 |
| **에포크 (Epochs)** | 5 | **6** | 충분한 학습 시간 확보 및 조기 종료 적용 |
| **드롭아웃** | 0.2 | **0.4** | 모델 규제 강화를 통한 과적합 방지 |

---

## 학습 곡선 분석 (Learning Curve)

### 1. Accuracy (정확도)
* **일반화 성능 확보**: Training Accuracy와 Validation Accuracy 사이의 간격이 좁게 유지됩니다. 
* **해석**: 모델이 학습 데이터에 편향되지 않고, 미학습 데이터(Unseen Data)에 대해서도 우수한 예측 성능을 보입니다.

### 2. Loss (손실도)
* **안정적 하강**: Training Loss가 지속적으로 우하향하며 학습이 정상적으로 진행되었습니다.
* **과적합 방지**: Validation Loss가 반등하기 직전인 **6회 에포크**에서 학습을 종료하여 일반화 성능을 극대화했습니다.

### 3. 성능 향상 포인트
* **성공적인 튜닝**: Validation Accuracy가 **약 73.4% 이상**을 기록하며, 기존 Baseline 대비 유의미한 수치 향상을 확인했습니다.

---

## 성능 지표 분석 (Evaluation Metrics)

추천의 정확도와 순위의 적절성을 평가한 결과, 모든 지표에서 성능 향상을 달성했습니다.

| 평가 지표 | 튜닝 전 (Baseline) | 튜닝 후 (Improved) | 개선 정도 (Delta) |
|:---|:---:|:---:|:---|
| **Hit Rate** | 0.63053 | **0.63365** | **+0.00312 (▲0.49%)** |
| **NDCG** | 0.66195 | **0.66752** | **+0.00557 (▲0.84%)** |

> [!NOTE]
> **Hit Rate (적중률) 개선**: 모델이 실제 정답 아이템을 추천 목록(Top-10) 내에 포함시키는 빈도가 늘어났습니다.
> **NDCG 개선**: 선호 아이템을 단순히 추천하는 것을 넘어, 상위권(Top-K 앞부분)에 더욱 정교하게 배치하고 있음을 증명합니다.

---

## 최종 요약

> 본 실습에서는 **임베딩 크기를 32로 확대, 학습률을 0.0005로 상향, 배치 사이즈를 1024로 조정**하고 **에포크를 6회로 최적화**하여 학습 곡선의 안정성을 확보했습니다. 이를 통해 모델의 과적합을 억제함과 동시에 유저의 선호도를 더욱 정밀하게 예측하는 고도화된 추천 모델을 도출하였습니다.
